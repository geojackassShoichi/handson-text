.. jubatus-handson documentation master file, created by
   sphinx-quickstart on Fri Jan 18 09:30:15 2013.
   You can adapt this file completely to your liking, but it should at least

=============================
 Jubatus ハンズオン テキスト
=============================


機械学習はデータに基づいて機械に「判断」を行なわせる技術
========================================================

- ざっくりとした説明
- 複数の選択肢から1つ選ぶのが「多値分類問題」
- 多値分類の簡単な説明
- 応用の簡単な説明
- 今日はこれをやります

JubatusはOSSの機械学習フレームワークです
========================================

- Jubatusの特徴をつらつらと
- Jubatusの分類器を起動しましょう
- 最初に手を動かす
- 起動コマンド、起動の仕方、起動したことの確認

今日は分散の話はしません
========================

- 機械学習の部分だけ解説
- 分散はしないことをつたえる


Jubatusを使ってみる
===================

サンプルを実行する
------------------

まずは、サンプルプログラムを実行してみます。
以下のURLからサンプルプログラムをダウンロードしてください。

では、実行してみましょう。

::

   $ python sample.py
   TODO 出力を表示

上記のような出力が出たら成功です。


サーバー・クライアントモデル
----------------------------

先のプログラムがどのように動いているのかを通じて、Jubatusの仕組みを解説します。
Jubatusは最初に実行した ``jubaclassifier`` をはじめとするサーバーと、サンプルプログラムを始めとするクライアントからなります。
この仕組のお陰で、C++で書かれたサーバーがデータの分析を行い、ユーザーサイドのクライアントはPythonやJavaなどの複数の言語から利用できます。

クライアントとサーバー間の通信は、 *msgpack* というデータシリアライズ形式を使った *msgpack-rpc* を利用しています。
各言語用のクライアントライブラリは、msgpack-rpcをラップして隠蔽しているため、ユーザーは何の通信プロトコルを利用しているか知る必要はありません。
クライアントライブラリで用意されているメソッドを呼び出すだけで、自動的に通信を行い、分析結果が得られます。


サンプルプログラムを読んでみる
------------------------------

さて、ここから自分でプログラムを書いてみましょう。
まず手始めに、サンプルプログラムを読んでみます。
非常に単純なサンプルです。

::

   TODO

ここでは Python のソースをベースに説明します。
他の言語のサンプルも概ね同じような構造を指定ます。

簡単に説明します。
分類器の学習には、「このデータはこの分類がされます」という *教師データ* を与える必要があります。
教師データは *正解データ* 、 *ラベル付きデータ* と呼ばれることもあります。
最初の行で用意しているのが、この教師データです。
教師データを使って、 ``jubaclassifier`` の ``train`` メソッドを呼び出しています。
``train`` メソッドは、教師データを与えて学習を行うためのメソッドです。

学習のステップが終わったら、未分類のデータを自動分類しています。
``classify`` メソッドは、未分類のデータを分類するためのメソッドです。
今まで学習したデータの傾向に照らしあわせて、同じ基準で分類を行います。

分類結果は ``classification_result`` という型で返ってきます。
TODO

サンプルを改造してみる
----------------------

サンプルプログラムの改造を通して、使い方の感触を得ましょう。
一番簡単な改良として、学習データを増やしてみます。
一般的に、学習データは大量にあったほうが分類精度は良くなります。
以下のように、学習データを増やしてみます。

TODO

いくつかのデータに対して、分類結果が変わりました。

学習データは増やせば増やすほど、基本的には分類精度の向上が期待されます。
ただし、追加したデータが今までと違う傾向があったりすると、精度が向上するどころか下がることもあるので注意しましょう。


次に、ラベルを追加してみます。
今まで TODO と TODO だけの分類でしたが、 TODO を更に2つに分けて、以下のように細かい分類にしてみます。

TODO

先程と同様に実行してみましょう。

TODO

一般的にラベル数を増やせば増やすほど、見かけ上の精度は下がることに注意しましょう。
分類の粒度が細かくなればなるほど、正しく当てるのが難しくなるためです。


設定を変更してみる
------------------

``jubaclassifier`` を起動する際に、 ``-f`` オプションで設定ファイルを渡したのを覚えているでしょうか。
起動時の設定には、どのような学習を行うか、どのようなパラメータ設定で行うかなどの重要なチューニングポイントが隠れています。
次に、この設定を修正することで機械学習のチューニングを行います。

まずは設定ファイルの全体像をみてみましょう。

::

   TODO 確認
   $ cat /usr/local/share/jubatus/example/config/classifier/pa.json
   {
     "converter" : {
       "string_filter_types" : {},
       "string_filter_rules" : [],
       "num_filter_types" : {},
       "num_filter_rules" : [],
       "string_types" : {},
       "string_rules" : [
         { "key" : "*", "type" : "str", "sample_weight" : "bin", "global_weight" : "bin" }
       ],
       "num_types" : {},
       "num_rules" : [
         { "key" : "*", "type" : "num" }
       ]
     },
     "parameter" : {
       "regularization_weight" : 1.0
     },
     "method" : "PA1"
   }

Jubatusの全てのサーバーの設定ファイルは、単一のJSONフォーマットです。
また、下記の設定項目の詳細は、 `ドキュメント <http://jubat.us/ja/api_classifier.html>`_ を参照してください。

.. csv-table::
   :header: "フィールド名", "説明"

   method, 利用する学習アルゴリズム名を指定します。
   parameter, 学習アルゴリズムに渡すパラメータを指定します。
   converter, 特徴変換の方法を指定します。

それぞれのパラメータを変更しながら、その役割を説明していきます。


学習アルゴリズムを変えてみる
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

教師付きデータがやってきた時に、機械学習の内部状態をどのように変更するのかを決めるのが学習アルゴリズムです。
Jubatusでは、データが1つやってくるたびに内部状態を変える、 *オンライン学習* という方式のアルゴリズムをサポートしています。

最初の設定では "PA1" という手法をとっていましたが、これを "AROW" に変えてみましょう。

::

   $ cp /usr/local/share/jubatus/example/config/classifier/pa.json ./my_conf.json
   $ vi my_conf.json
   $ jubaclassifier -f my_conf.json

実行結果の幾つかが変わりました。

"PA1" というのは Passive Aggressive という手法で、2003年に初めて提案されました。
また、 "AROW" は Adaptive Regularization Of Weight vector という手法で、2009年に提案されました。
このアルゴリズムの詳細は理解しなくても使えます。
おまけで少しだけ紹介すると、 PA-1 は以下の更新式を使って内部パラメータを更新します。

一方の AROW では以下の更新式を使います。


その他にも NHERD や CW などの手法も利用できますが、詳細はドキュメントに譲ります。
他の手法も試して、精度にどのような影響があるのか確認するのも良いでしょう。
なお、利用するアルゴリズムは実行途中で変えることができません。


パラメータを変えてみる
~~~~~~~~~~~~~~~~~~~~~~

一般に、学習アルゴリズムは内部に大量の（数万、数十万という様なオーダー）パラメータを持っており、教師データにもとづいてこれを調整します。
しかし、多くのアルゴリズムはこれとは別に、学習前にパラメータを渡します。
この学習前に与えるパラメータは、どのくらい積極的に学習するかなどの制御に使われます。
教師データを使って調整されないため、自動調整されるパラメータとは区別されて *ハイパーパラメータ* と呼ばれることもあります。

ハイパーパラメータの役割はいくつかありますが、現在分類器にあるハイパーパラメータはデータに対する感度の制御に使われています。
感度が高いと、学習は早く進む代わりにノイズに弱くなります。
一方、感度が低いと、学習が遅くなる代わりにノイズに負けなくなります。
このトレードオフの調整は難しく、実験的に良い塩梅のパラーメータを探ることがよく行なわれます。

では、ハイパーパラメータを上下させてみましょう
設定ファイルの ``regularization_weight`` を変えてみましょう。

TODO

この状態で実行すると、結果が変わります。

適切なハイパーパラメータはデータの種類やデータの量によっても変わります。
また、ハイパーパラメータも自動で調整する様な手法もあるのですが、Jubatusにはまだ実装されていません。


特徴抽出の設定です
~~~~~~~~~~~~~~~~~~

残りの設定、すなわち ``converter`` の部分は特徴抽出の設定です。
特徴抽出は解析がうまくいくかどうかを左右する非常に重要なポイントなので詳しく説明します。

一般的に、機械学習の技術は入力データとしてテキストや画像といった生の情報を扱いません。
普通は数値情報に落ちた、ベクトルの形式のデータを扱うことがほとんどです。
では、どうやって文や画像、行動履歴などのデータを扱うのでしょう？
この間に入るのが特徴抽出（あるいは特徴変換）といわれる処理です。
入力データと解析対象に応じて、入力データの生の文や画像はベクトル形式に変換されます。
機械学習技術の多くがベクトルデータを入力として仮定しているため、一度ベクトルデータに変換してしまえば元々の入力が文であっても画像であっても同じように処理ができます。

TODO

普通の機械学習ライブラリではこの特徴抽出の仕組を備えていません。
そんため、ユーザーは特徴抽出処理を自分で書かなければなりませんでした。
Jubatusではこの特徴抽出処理の仕組みも備えているため、ユーザーは生のデータを直接Jubatusに入力しても機械学習を利用できるのです。


デフォルトの設定では元の入力をそのまま使っています
==================================================


- どういう変換をしているのかを図解

特徴の取り方を工夫することで分類精度が変わります
================================================

- 単語に分割する場合の図解

スペース区切りで特徴をとってみましょう
======================================

- スペース区切りを使う場合の設定
- 設定を変えて実行

文字情報のみを使ってみましょう
==============================

- bigramを使う例

その他の設定はWebサイトを参照してください
=========================================

- リンクを

自由に改変してみましょう
========================

- あとは自由



Indices and tables
==================

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`

